# ğŸ’¸ Income Prediction Using Machine Learning + Streamlit Web App

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-Deployment-brightgreen)
![Machine Learning](https://img.shields.io/badge/Model-Gradient%20Boosting-orange)

Predict whether a person earns **more than \$50K per year** based on demographic and employment data, using multiple classification algorithms trained on the **UCI Adult Income dataset**.

---

## ğŸ”¥ Project Highlights

- Built as part of my **AI/ML Internship Project at ICT Academy**
- Complete pipeline: **Data Cleaning â†’ EDA â†’ Model Training â†’ Evaluation â†’ Deployment**
- Integrated **Streamlit UI** for real-time predictions

---

## ğŸš€ Live Demo

> _(Coming Soon)_ Will be hosted on **Streamlit Cloud** or Hugging Face Spaces.  
> **[View Demo](#)**

---

## ğŸ–¼ Preview

> Add screenshot after hosting  
> `![UI Preview](screenshot.png)`

---

## ğŸ”§ Tools & Libraries

- **Language**: Python  
- **Libraries**: Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, XGBoost  
- **Deployment**: Streamlit  
- **Platform**: Google Colab (for training) + Local/Cloud (for deployment)

---

## ğŸ¤– Machine Learning Models Used

| Model                  | Notes                             |
|------------------------|-----------------------------------|
| Logistic Regression    | Baseline classifier               |
| k-Nearest Neighbors    | Distance-based                     |
| Support Vector Machine | Kernel trick for non-linearity     |
| Decision Tree          | Easy to interpret                  |
| Random Forest          | Ensemble of trees                  |
| Gradient Boosting      | Boosted sequential learning        |
| **XGBoost**            | Extreme boosting, regularized      |

---

## ğŸ† Best Performing Model

| Metric        | Value     |
|---------------|-----------|
| **Model**     | Gradient Boosting |
| **Accuracy**  | 83.8%     |
| **Precision** | 0.83      |
| **Recall**    | 0.84      |
| **F1-Score**  | 0.83      |

âœ… Gradient Boosting achieved the best balanced performance, making it ideal for income prediction tasks.

---

##  Key Steps in Notebook

1. **Data Cleaning**: Missing values, whitespace removal in categorical features  
2. **EDA**: Visualized distributions, correlations (e.g., income vs. education)  
3. **Feature Encoding**: Label Encoding & One-Hot Encoding for categorical data  
4. **Feature Scaling**: Standardized numerical features  
5. **Model Training**: Tested 7+ algorithms  
6. **Evaluation**: Confusion matrix, precision/recall, F1-score

---

## ğŸ“ Repository Structure

Income-Prediction-ML/
â”‚
â”œâ”€â”€ app.py # Streamlit web app
â”œâ”€â”€ income_pipeline.pkl # Trained pipeline (preprocessing + model)
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ Income_Prediction_ML.ipynb # Notebook (EDA + model training)
â””â”€â”€ README.md # Project documentation


---

## ğŸ— How to Run Locally

### Run Notebook (Model Training)
- Open `Income_Prediction_ML.ipynb` in **Google Colab**
- Execute step-by-step for:
  - Data loading
  - Preprocessing
  - Model training & evaluation

### Run Streamlit UI (Prediction)
```bash
# Clone repo
git clone https://github.com/Thoibasaleem/Income-Prediction-ML.git
cd Income-Prediction-ML

# Install dependencies
pip install -r requirements.txt

# Run app
streamlit run app.py
##  Real-World Application

#This project mimics real-world binary classification problems such as:
- Credit risk prediction
- Loan approval systems
- Customer segmentation

## ğŸ“‡ Connect With Me

- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/thoiba-saleem/)
- ğŸ“¬ Email: thoibasaleem389@gmail.com
- ğŸ’» GitHub: [ThoibaSaleem](https://github.com/ThoibaSaleem)
